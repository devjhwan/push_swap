# Push Swap Rebuild (KOR)

이전에 push_swap을 하면서 참 골때리는 상황이 자주 나왔었다. 나는 4년제 대학을 다니며 이미 알고리즘에 대해 어느정도 숙지한 상태였기 때문에 알고리즘 자체를 공부하는 데에는 큰 시간을 들이지 않았지만 그게 오히려 도전욕구를 불러일으켜 내가 할 수 있는 최대한으로 최적화를 하느라 한달을 넘게 이 프로젝트를 붙잡고 있었다.

이전에 push_swap을 진행하며 만들었던 연구 노트는 이 링크에 있다.

[Push Swap](https://www.notion.so/Push-Swap-947ce292fc4147fcb82b5679df02aab3?pvs=21)

이때에 아마도 4500개 이하로 정렬하는데 성공했던걸로 기억한다. 하지만 push_swap프로젝트를 진행하며 여러 사이트와 슬랙을 탐독하며 정보를 모으던 도중 슬랙의 한 쓰래드가 기억에 남는다. 어떤 사람이 본인은 명령어 3500개 이하로 정렬하는데 성공을 했다는 자랑글을 올렸는데 그때에도 사람들이 반신반의하며 그게 가능한지 서로 토론하는 그런 글이었다.

나는 그 글을 보면서 잠시 계산을 해보았다. n = 500일 때에 $y = n * x * log_2(n)$ 에서 y가 3500이 되는 x의 값을 계산해보니 x가 0.78쯔음… 즉 약 4/5쯔음이 나와야 하는데 내가 한 최적화 방법으로는 무슨 수를 써도 1이하로 내릴 수가 없었다. 퀵소트나 라직스 머지 등등의 알고리즘으로는 이를 해결할 수 없다는 것을 그때 깨달았다.

그래서 발상을 전환시켜 그때 듣던 수업중 인공지능에 관한 수업을 떠올렸다. 체스 인공지능을 만드는게 과제였던 수업인데, 각각의 체스 판의 기물 상태를 하나의 노드로 만들어 컴퓨터에게 학습시켜서 가장 좋은 수를 두도록 인공지능을 개발하는 수업이었다. 난 여기에 착안하여 push_swap의 스택들도 노드로 만들어 그래프 탐색 알고리즘을 사용하면 되지 않을까? 라는 발상을 떠올렸다.

그렇지만 과거의 나는 이미 한달간의 프로젝트 진행으로 인해 진이 빠진 상태였고 미래에 프로젝트 휴식기에 도전해보자 라고 생각하며 기억 속 구석에 이 아이디어를 박아두고 있었다.

지금에서야 도전하는 이유는 42에 minishell 구간에 도착했고 팀원을 구하기 전 잠시 학업에 집중하며 지내다가 잠시 쉬는 시간에 갑자기 이 아이디어가 수면 위로 부상했다. 그때완 달리 여러 프로젝트들을 진행하며 코드 짜는 실력이 객관적으로 늘었고 그때보단 더 쉽게 프로젝트를 진행할 수 있지 않을까? 라는 자신감이 생겨 다시금 도전하게 되었다.

만약 이 글을 읽는 사람중에 아직 push_swap을 도전하지 않은 사람이 있다면 우선 평범한 정렬 알고리즘으로 과제를 수행한 다음 시도해보기 바란다.

이번엔 libft와 ft_printf을 사용하지 않으며 프로젝트에 필요한 함수들만 그때그때 만들며 진행할 예정이다. 왜냐하면 이번엔 스택을 만들 때에 연결 리스트가 아닌 일반 배열로 만들 예정이고 또한 프로젝트를 진행하며 ft_printf를 사용할 일이 전혀 없었기 때문이다. libft함수 중 태반이 사용하지 않는 함수이고 매번 컴파일 할때에 libft 파일들 컴파일 하는 시간이 지겹게 느껴졌기 때문에 과감히 제외하기로 결정했다.

과제를 시작하기에 앞서 우선적으로 그래프 탐색에 효율적인 알고리즘을 검색해 보았다. 여러 알고리즘들을 봤고 그 작동원리를 살펴보았지만 역시나 A*알고리즘이 가장 효율적인 것 같았다. 노드의 깊이가 증가할수록 (명령어 개수)^깊이 순으로 노드가 증가하니 최대 3500개의 깊이까지 감당하려면 모든 노드를 탐색하는 종류의 알고리즘은 모두 제외시켰다.

하지만 BFS는 조금 다르게 보았다. 내가 이 알고리즘을 눈여겨본 이유는 이는 브루트 포스 알고리즘 종류로 시간과 메모리 자원만 충분하다면 100%의 최적 경로를 나타내기 때문이다. 내가 기억하기로 평가 항목중에 3개와 5개 단위 평가가 있었는데 이를 BFS알고리즘으로 처리해버리면 깔끔하게 정리가 될 거라고 판단했다. 알고리즘 코딩 후 여러 실험을 거쳐야겠지만 명령어 8~10개까지는 무리 없이 처리 가능할거라고 판단한다. 물론 그 이상은 무리다.

각 노드는 스택 A, B 그리고 알고리즘에 따라서 다른 변수들이 삽입될 예정이다. 

![Untitled](Push%20Swap%20Rebuild%20(KOR)%206475813b551648a98135e57806594dc3/Untitled.png)

![Untitled](Push%20Swap%20Rebuild%20(KOR)%206475813b551648a98135e57806594dc3/Untitled%201.png)

메모리를 따져보면 각 스택당 스택 포인터 + int 4개 + arr 포인터 + arr 내부 값(n) = 8 + 4 * 4 + 8 + 4 * n = 32 + 4 * n이며 각 노드당 노드 포인터 + 스택 2개 = 8 + 2 * (32 + 4 * n) = 72 + 8 * n이다.

n = 500이라고 치고 노드를 20000개까지 탐색했다고 하면 20000 * (72 + 8 * 500) = 81,440,000 약 81 Mb다. 내부적으로 메모리를 조금 더 사용할 수는 있다고 해도 이정도는 충분히 힙 영역에서 충분히 감당하고도 남는 용량이라고 생각한다. 또한 탐색 과정에 따라 노드의 삭제도 가능하니 메모리 영역에서는 문제가 없다고 판단된다.

휴리스틱은 현 노드에서 목표 노드(정렬된 상태)간의 유사성으로, 각 노드간의 거리는 노드간의 휴리스틱 차이로 생각을 해 보았다. 이는 문자열 편집거리 (레벤스테인 거리)와 유사하게 생각을 해 보았다. 접근 방식은 동일하다 수행 가능한 명령어 갯수의 차이와 한정된 메모리 공간으로 인해 레벤스테인 거리는 사용하지 못하지만 그 방식을 일부 차용할 수는 있을 것 같다.

노드간의 유사성을 검사하기 위해 LCS 알고리즘이나 스피어만 상관계수를 사용할 것 같다. 아마 프로젝트를 진행하면서 둘 중 하나를 고르게 될 것이다. 일반적인 상황이라면 스피어만 상관계수를 선택해 노드간의 유사성을 더 정확하게 나타내겠지만 문제는 스택이 두개라는 것이다.

스택이 한개라면 전체 숫자의 갯수는 목표 노드와 동일함으로 계산이 쉽지만 대부분의 경우 2개의 스택에 숫자들이 분포되어 있을 것이기 때문에 일반적인 알고리즘으로는 계산에 오류가 날 것이다.

지금 당장 생각나는 방법으로는 LCS방법을 채택하고 목표 노드에 스택 A는 정렬된 상태 스택 B는 같은 숫자들이지만 반대로 정렬된 상태의 노드를 만들고 스택 A의 LCS와 스택 B의 LCS의 합으로 유사성을 검사하는 방식을 쓰는 것이다. 이는 어찌보면 모래시계 알고리즘과도 비슷한 점이 있다고 생각한다. 만약 이 방법을 채택하게 된다면 가장 먼저 나올 명령어는 대부분 pb 일 것이다. 왜냐하면 스택 A에서 LCS는 숫자 하나가 빠진다고 달라질 확률이 적지만 스택 B에 숫자 하나가 들어오면 확정적으로 LCS가 하나 늘기 때문이다.

일단 첫 단계로 여기까지 정리를 해 두었고 지금부터는 알고리즘을 짜며 기초적인 실험들을 진행해야겠다. 알고리즘을 짜다보면 생각하지 못한 허점들이 발견되고 처음부터 갈아엎어야 할 수 도 있기 때문에 첫 코딩을 짠 이후 다시 돌아와 정리를 하겠다.